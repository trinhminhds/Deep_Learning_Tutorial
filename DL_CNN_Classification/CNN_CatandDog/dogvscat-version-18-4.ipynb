{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5441,"databundleVersionId":38425,"sourceType":"competition"},{"sourceId":28903,"sourceType":"datasetVersion","datasetId":22535},{"sourceId":30378,"sourceType":"datasetVersion","datasetId":23777},{"sourceId":1569529,"sourceType":"datasetVersion","datasetId":927555}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow==2.13.0","metadata":{"execution":{"iopub.status.busy":"2024-04-19T13:03:29.858249Z","iopub.execute_input":"2024-04-19T13:03:29.858723Z","iopub.status.idle":"2024-04-19T13:05:29.441556Z","shell.execute_reply.started":"2024-04-19T13:03:29.858688Z","shell.execute_reply":"2024-04-19T13:05:29.439726Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.13.0\n  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (23.5.26)\nCollecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0)\n  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.60.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (3.10.0)\nCollecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (16.0.6)\nCollecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13.0)\n  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.16.0)\nCollecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (2.4.0)\nCollecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0)\n  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.0) (0.35.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.26.1)\nCollecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0)\n  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.13.0) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\nDownloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nDownloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\nInstalling collected packages: typing-extensions, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.9.0\n    Uninstalling typing_extensions-4.9.0:\n      Successfully uninstalled typing_extensions-4.9.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.15.0\n    Uninstalling tensorflow-estimator-2.15.0:\n      Successfully uninstalled tensorflow-estimator-2.15.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: keras\n    Found existing installation: keras 3.1.1\n    Uninstalling keras-3.1.1:\n      Successfully uninstalled keras-3.1.1\n  Attempting uninstall: gast\n    Found existing installation: gast 0.5.4\n    Uninstalling gast-0.5.4:\n      Successfully uninstalled gast-0.5.4\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-nlp 0.8.2 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nsqlalchemy 2.0.25 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\nalbumentations 1.4.0 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\nfastapi 0.108.0 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\nfeaturetools 1.30.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\njupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npydantic 2.5.3 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\npydantic-core 2.14.6 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.13.0 which is incompatible.\ntensorflow-serving-api 2.14.1 requires tensorflow<3,>=2.14.1, but you have tensorflow 2.13.0 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.13.0 which is incompatible.\ntensorstore 0.1.56 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.13.0 which is incompatible.\ntypeguard 4.1.5 requires typing-extensions>=4.7.0; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\nwoodwork 0.29.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nxarray 2024.3.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-1.24.3 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"class color:\n    BOLD = '\\033[1m'\n    BOLD_COLOR = '\\033[1m' + '\\033[34m'\n    END = '\\033[0m'\n\nprint(color.BOLD_COLOR + '\\nImporting requeid libararies......\\n' + color.END)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport zipfile \nimport glob\nimport os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport missingno as msno\n\nfrom keras.preprocessing.image import (\n    ImageDataGenerator,img_to_array,array_to_img,load_img\n)\n\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import (\n    confusion_matrix,classification_report,\n    accuracy_score,f1_score,roc_auc_score\n)\n\nimport tensorflow as tf\nfrom keras.models import Model,Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dropout,Dense,Flatten\n\nfrom keras.applications import resnet50\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras import optimizers\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping,LearningRateScheduler\n\nfrom keras import backend as K\nK.clear_session()\n\n\nfrom IPython.display import SVG\nfrom keras.utils import model_to_dot\nfrom keras.utils import plot_model\n\n\nfrom sklearn.utils import shuffle\n\nprint('Tensorflow Version: ' + tf.__version__)\nprint(color.BOLD_COLOR + '\\nDone!!!' + color.END)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T13:05:41.931674Z","iopub.execute_input":"2024-04-19T13:05:41.932194Z","iopub.status.idle":"2024-04-19T13:05:52.121019Z","shell.execute_reply.started":"2024-04-19T13:05:41.932153Z","shell.execute_reply":"2024-04-19T13:05:52.119256Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[1m\u001b[34m\nImporting requeid libararies......\n\u001b[0m\nTensorflow Version: 2.13.0\n\u001b[1m\u001b[34m\nDone!!!\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"print('\\n' + color.BOLD_COLOR + 'Extracting the data from dataset.....' + color.END + '\\n')\n\nzip_files = glob.glob('/kaggle/input/dogs-vs-cats-redux-kernels-edition/*.zip')\n\nprint('{} files found in the input directory'.format(color.BOLD + str(len(zip_files)) \n                                                     + color.END)+'\\n')\n\nfor file in zip_files:\n    with zipfile.ZipFile(file,'r') as Z:\n        Z.extractall('data')\n    print('{} is extracted'.format(color.BOLD + file.split('/')[-1] + color.END) + '\\n')\n    \nprint(color.BOLD_COLOR + 'Extraction is completed' + color.END + '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/working/data/train'\ntest_dir = '/kaggle/working/data/test'\n\nprint(color.BOLD_COLOR + 'Total Images in Train, and Test Data....' + color.END)\nprint('\\n' + color.BOLD_COLOR + 'No. of Train Images: ' + color.END + color.BOLD +\n     str(len(os.listdir(train_dir))) + color.END)\nprint('\\n' + color.BOLD_COLOR + 'No. of Test Images: ' + color.END + color.BOLD +\n     str(len(os.listdir(test_dir))) + color.END)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def category(path):\n    return [file.split('.')[0]for file in os.listdir(path)]\n\ndef filename(path):\n    return [file for file in os.listdir(path)]\n\n\nx_train_imgname = filename(train_dir)\nx_test_imgname = filename(test_dir)\ny_train_label = category(train_dir)\n\nprint('\\n' + color.BOLD_COLOR + 'Image data is storing into dataframes...' + color.END + '\\n')\n\ntrain_image_df = pd.DataFrame({'filename': x_train_imgname,'category': y_train_label})\nsubmission_image_df = pd.DataFrame({'filename': x_test_imgname})\n\nprint('Training image names and labels are read to ' + color.BOLD_COLOR \n      + 'train_image_df' + color.END + '\\n')\n\nprint('Testing image names are read to ' + color.BOLD_COLOR\n      + 'submission_image_df' + color.END + '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(color.BOLD_COLOR + '\\n' + 'Helper funtion for image path,id,category data extractions and Image visualizations' + '\\n' +color.END)\n\ndef img_path(directory):\n    '''\n    This funtion extracs image ids,category, and image paths from directory.\n    input:\n    directory: Path to location of images\n    Return:\n    ID_no: list of image ids\n    Paths: list of image paths\n    cate: list of image category\n    '''\n    \n    paths = []\n    cate = []\n    ID_no = []\n    for file in os.listdir(directory):\n        path = os.path.join(directory,file)\n        paths.append(path)\n        cate.append(file.split('.')[0])\n        ID_no.append(file.split('.')[1])\n    return ID_no,paths,cate\n\ndef showImages(data,num_row = 3,num_col = 3, name = 'any',subtitle = 'off'):\n    '''\n    This funtion creates a grid of image from dataset.\n    Shuffled images will be displayed.\n    \n    Input:\n    num_row : default : 3, no. of rows in a grid\n    num_col : default : 3, no. of cols in a grid\n    data: Dataframe of paths\n    name: default 'any',takes : cat,dog,any or something else would give both \n    subtitle : default id number for each image, default : 'off',takes: 'on' and 'off'\n    Return: Node\n    '''\n    \n    \n    cat_df,dog_df = data[data['Category'] == 'cat'],data[data['Category'] == 'dog']\n    \n    if name == 'dog':\n        X,Y = dog_df['img_paths'],dog_df['ID_no']\n    elif name == 'cat':\n        X,Y = cat_df['img_paths'],cat_df['ID_no']\n    else:\n        X,Y = data['img_paths'], data['ID_no']\n        \n        \n    (X_rand,Y_rand) = shuffle(X,Y)\n    \n    \n    fig,ax = plt.subplots(num_row,num_col,figsize=(12,12),dpi = 100)\n    fig.patch.set_facecolor('#f5f6f6')\n    axes = ax.ravel()\n    \n    for idx,ax in enumerate(axes):\n        x = load_img(X_rand.iloc[idx],target_size=(125,125))\n        ax.imshow(x)\n        if subtitle  == 'on':\n            ax.set_title('{}'.format(Y_rand.iloc[idx]))\n        else:\n            ax.set_title('')\n        ax.axis('off')\n        plt.subplots_adjust(wspace = 0)\n        del x\n        \n    fig.text(0.1,0.93,'Hey Siri! is it a Cat or Dog ? : {}s from Training Data'.format(\n        name.capitalize()), {'fontfamily':'serif','size': 18,'weight': 'bold'})\n        \n    return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ID_no,img_paths,train_images = img_path(train_dir)\n\nprint('\\n' + color.BOLD_COLOR + 'Dataframe is creating for training image visualization in a gird....'\n      + color.END + '\\n')\n\nvisual_df = pd.DataFrame({'ID_no':ID_no,'Category':train_images,'img_paths':img_paths})\n\nprint(visual_df.head(5))\n\nprint('\\n' + color.BOLD_COLOR + 'Done!' + color.END + '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showImages(visual_df,5,5,name = 'dog', subtitle='off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showImages(visual_df,5,5,name = 'cat', subtitle='off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showImages(visual_df,5,5,name = 'Dog and Cat', subtitle='off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_valid_df, test_df = train_test_split(train_image_df,test_size = 0.04)\ntrain_df, valid_df = train_test_split(train_valid_df,test_size = 0.2)\n\ntrain_images = train_df.shape[0]\nvalid_images = valid_df.shape[0]\nholdon_images = test_df.shape[0]\ntest_images = submission_image_df.shape[0]\n\n\nprint('\\n' + color.BOLD_COLOR + 'Number of Traning Images: ' + color.END  \n      + str(train_images) + color.END)\nprint('\\n' + color.BOLD_COLOR + 'Number of Validating Images: ' + color.END\n     + str(valid_images) + color.END)\nprint('\\n' + color.BOLD_COLOR + 'Number of Holdon Images: ' + color.END \n      + str(holdon_images) + color.END)\nprint('\\n' + color.BOLD_COLOR + 'Number of Testing Images: ' + color.END\n     + str(test_images) + color.END)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 224\nbatch_size = 128\n\nprint(color.BOLD_COLOR + '\\nPreparing train and validation images for training...' + color.END)\n\ntrain_map = ImageDataGenerator()\nvalid_map = ImageDataGenerator()\ntest_map = ImageDataGenerator()\n\nprint(color.BOLD)\n\nvani_train_data = train_map.flow_from_dataframe(\n    train_df,train_dir,\n    x_col = 'filename',\n    y_col = 'category',\n    target_size = (img_size,img_size),\n    batch_size = batch_size,\n    class_mode = 'categorical'\n)\n\nvani_valid_data = valid_map.flow_from_dataframe(\n    valid_df,train_dir,\n    x_col = 'filename',\n    y_col = 'category',\n    target_size = (img_size,img_size),\n    batch_size = batch_size,\n    class_mode = 'categorical'\n)\n\nvani_test_data = test_map.flow_from_dataframe(\n    test_df,train_dir,\n    x_col = 'filename',\n    y_col = None,\n    target_size = (img_size,img_size),\n    batch_size = batch_size,\n    class_mode = None,\n    shufle = False\n)\n\n\nprint(color.BOLD_COLOR + '\\nDone!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vani_model = Sequential()\n\nvani_model.add(Conv2D(16,(3,3),activation = 'relu',padding = 'same',input_shape = (224,224,3)))\nvani_model.add(Conv2D(16,(3,3),activation = 'relu',padding = 'same'))\nvani_model.add(MaxPooling2D(pool_size = (2,2),strides = (2,2)))\n\nvani_model.add(Conv2D(32,(3,3),activation = 'relu', padding = 'same'))\nvani_model.add(Conv2D(32,(3,3),activation = 'relu',padding = 'same'))\nvani_model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n\nvani_model.add(Conv2D(64,(3,3),activation = 'relu',padding = 'same'))\nvani_model.add(Conv2D(64,(3,3),activation = 'relu',padding = 'same'))\nvani_model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n\nvani_model.add(Conv2D(128,(3,3),activation = 'relu',padding = 'same'))\nvani_model.add(Conv2D(128,(3,3),activation = 'relu',padding = 'same'))\nvani_model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n\nvani_model.add(Dropout(0.3))\n\nvani_model.add(Conv2D(256,(3,3),activation = 'relu',padding = 'same'))\nvani_model.add(Conv2D(256,(3,3),activation = 'relu',padding = 'same'))\nvani_model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n\nvani_model.add(Dropout(0.3))\n\nvani_model.add(Flatten())\nvani_model.add(Dense(512,activation = 'relu'))\nvani_model.add(Dropout(0.5))\nvani_model.add(Dense(2,activation = 'softmax'))\n\nprint(color.BOLD_COLOR + '\\nVanilla Model layers and output shapes with params....\\n' + color.END)\n\nvani_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(vani_model,show_shapes = True,expand_nested = True,dpi = 80)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = 'categorical_crossentropy'\nopt = tf.keras.optimizers.Adam(learning_rate = 0.0001,beta_1 = 0.9,beta_2 = 0.999,epsilon =1e-07)\nmetrics = ['accuracy']\n\nvani_model.compile(loss = loss,optimizer = opt,metrics = metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(color.BOLD_COLOR + 'Traning on Vanilla CNN has started....\\n' + color.END)\n\nvani_hisory = vani_model.fit(vani_train_data,epochs = 15,\n                            validation_data = vani_valid_data,\n                            validation_steps = valid_images//batch_size,\n                            steps_per_epoch = train_images//batch_size\n LinearSegmentedColormap                        )\n\nprint(color.END)\nprint(color.BOLD_COLOR + '\\nDone!\\n' + color.END)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots(2,1,figsize=(8,8),dpi = 100)\nfig.patch.set_facecolor('#f5f6f6')\n\naxes = ax.ravel()\n\nfor ax in axes:\n    ax.set_facecolor('#f5f6f6')\n    for loc in ['right','top']:\n        ax.spines[loc].set_visible(False)\n\nhist1 = vani_hisory.history\nEpochs = range(len(hist1['loss']))\n\nsns.lineplot(x = Epochs,y = hist1['val_loss'],ax = axes[0],linewidth = 4,color = colors[0])\nsns.lineplot(x = Epochs,y = hist1['loss'],ax = axes[0],linewidth = 4,color = colors[1])\n\naxes[0].text(Epochs[-1] + 0.25,hist1['val_loss'][-1],'Validation Loss',\n             {'fontfamily':'serif','size':12,'weight':'bold','color':colors[0]})\n\naxes[0].text(Epochs[-1] + 0.25,hist1['loss'][-1],'Training Loss',\n             {'fontfamily':'serif','size':12,'weight':'bold','color':colors[1]})\n\nsns.lineplot(x = Epochs,y = hist1['val_accuracy'],ax = axes[1],linewidth = 4,color = colors[0])\nsns.lineplot(x = Epochs,y = hist1['accuracy'],ax = axes[1],linewidth = 4,color = colors[1])\n\naxes[1].text(Epochs[-1] + 0.25,hist1['val_accuracy'][-1],'Validation Accuracy',\n             {'fontfamily':'serif','size':12,'weight':'bold','color':colors[0]})\n\naxes[1].text(Epochs[-1] + 0.25,hist1['accuracy'][-1],'Training Accuracy',\n             {'fontfamily':'serif','size':12,'weight':'bold','color':colors[1]})\n\nfig.text(0,1.06,'Hey Siri! is it a Cat or Dog?: Vanilla Loss and Accuracy',\n         {'fontfamily': 'serif','size':18,'weight':'bold'})\n\nfig.text(0,1.01,'Clearly There is a overfitting with this model,'  \n         + '\\nmay be transfer learning should correct this issue',\n         {'fontfamily': 'serif','size':12})\n\nfig.text(0.75,-0.05,'Made by trinhminh/Kaggle',\n         {'fontfamily':'serif','size':10,'color':'black'})\n\n\nplt.tight_layout(h_pad = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vani_pred = vani_model.predict_generator(vani_test_data)\ntest_df['vani_pred'] = np.argmax(vani_pred,axis = -1)\nlabels = dict((v,k) for k,v in vani_train_data.class_indices.items())\n\ntest_df['vani_pred'] = test_df['vani_pred'].map(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_confusion_matrix(cf,group_names = None,categories = 'auto',\n                          count = True,percent = True,cbar = True,\n                          xyticks = True,xyplotlabels = True,\n                          sum_stats = True,figsize = None,\n                          cmap = 'Blues', title = None):\n    \n    blanks = ['' for i in range(cf.size)]\n    \n    if group_names and len(group_names)==cf.size:\n        group_labels = ['{}\\n'.format(value) for value in group_names]\n    else:\n        group_labels = blanks\n        \n    \n    if count: \n        group_counts = ['{0:0.0f}\\n'.format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n    \n    \n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n    else:\n        group_percentages = blanks\n        \n    box_labels = [f\"{v1}{v2}{v3}\".strip()for v1,v2,v3 in zip (\n        group_labels,group_counts,group_percentages\n    )]\n    \n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n    \n    if sum_stats:\n        accuracy = np.trace(cf)/float(np.sum(cf))\n        \n        if len(cf)==2:\n            precision = cf[1,1] / sum(cf[:,1])\n            recall = cf[1,1] / sum(cf[1,:])\n            f1_score = 2*precision*recall / (precision + recall)\n            stats_text = '\\n\\nAccyracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}'.format(\n                accuracy,precision,recall,f1_score)\n        else:\n            stats_text = '\\n\\nAccuracy={:0.3f}'.format(accuracy)\n    else:\n        stats_text = \"\"\n        \n    \n    if figsize==None:\n        figsize = plt.rcParams.get('figute.figsize')\n        \n    if xyticks==False:\n        categoris=False\n        \n        \n    fig = plt.figure(figsize = figsize)\n    fig.patch.set_facecolor('#f5f6f6')\n    sns.heatmap(cf,annot = box_labels,fmt=\"\",linewidths = 1,square = True,linecolor = '#f5f6f6',\n               cmap = cmap,cbar=cbar,annot_kws={'fontfamily': 'serif','size':18,'weight':'bold'},\n               xticklabels = categories,\n               yticklabels = categories)\n    \n    if xyplotlabels:\n        plt.ylabel('True label', **{'fontfamily':'serif','size':12,'weight':'bold'})\n        plt.xlabel('Predicted label' + stats_text,**{'fontfamily':'serif','size':12,'weight':'bold'})\n    else:\n        plt.xlabel(stats_text,**{'fontfamily':'serif','size':12,'weight':'bold'})\n        \n    plt.gca().set_xticklabels(categories,fontdict={'fontfamily':'serif','size':16,'weight':'bold'})\n    plt.gca().set_yticklabels(categories,fontdict={'fontfamily':'serif','size':16,'weight':'bold'})\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vani_cf_matrix = confusion_matrix(test_df['category'],test_df['vani_pred'])\nmy_cols = [colors[0],colors[1]]\n\nlabels = ['True Neg','False Pos','False Neg','True Pos']\ncategories = ['Cat','Dog']\nmake_confusion_matrix(vani_cf_matrix,figsize=(10,5),\n                     group_names = labels,cbar = False,\n                     cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\",my_cols),\n                     categories = categories,\n                     title = 'Vanila CNN comfusion matrix')\n\nplt.gcf().text(0,1.1,'Hey Siri! is it a Cat or Dog?: Vanilla CNN Test Data Evaluation',\n               {'fontfamily':'serif','size': 24,'color':'black','weight':'bold'})\n\nplt.gcf().text(0,0.995,'It seem even vanilla CNN did a fair job considering parameters trained.'\n               + '\\nLest see how pre-trained model does the job...',\n               {'fontfamily':'serif','size':14,'color':'black'})\n\nplt.gcf().text(0.85,-0.15,'Made by trinhminh/Kaggle',\n               {'fontfamily':'serif','size':12,'color':'black'})\n\nplt.gcf().show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(color.BOLD + '\\n' + 'Helper funtions for Image Agumentation visualizations' + '\\n' + color.END)\n\ndef data_argumentation_show(n,gird_size):\n    \n    sample_aug_map = ImageDataGenerator(\n        rotation_range = 25,\n        horizontal_flip = True,\n        height_shift_range = 0.2,\n        width_shift_range = 0.2,\n        fill_mode = 'nearest',\n        rescale = 1/255\n    )\n    \n    sample_data = sample_aug_map.flow_from_dataframe(\n        (train_df.sample(n)),\n        train_dir,\n        x_col = 'filename',\n        y_col = 'category',\n        target_size = (img_size,img_size),\n        class_mode = 'categorical'\n    )\n    \n    fig = plt.figure(figsize=(10,10))\n    fig.patch.set_facecolor('#f5f6f6')\n    for i in range(0,gird_size*gird_size):\n        plt.subplot(gird_size,gird_size,i+1)\n        for x,y in sample_data:\n            img = x[0]\n            plt.imshow(img)\n            plt.axis('off')\n            break\n            plt.tight_layout()\n            del img\n            \n    plt.show()\n    \n    fig.text(0.1,0.93,'Hey Siri! it is cat or dog ?: Image agumentation',\n             {'fontfamily':'serif','size':20,'weight':'bold'})\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_argumentation_show(1,5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_argumentation_show(5,5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(color.BOLD_COLOR + '\\nSetting a decay learning rate for learning rate schedule\\n' + color.END)\n\nepoch = 50\nlearning_rate = 3e-5\nlr_start = 0.00000001\nlr_min = 0.000001\nlr_max = 3e-5\nlr_rampup_epochs = 1\nlr_sustain_epochs = 1\nlr_exp_decay = .8\n\ndef lrfn(epoch):\n    if epoch < lr_rampup_epochs:\n        lr = (lr_max - lr_start)/lr_rampup_epochs * epoch + lr_start\n    elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n        lr = lr_max\n    else:\n        lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs)+ lr_min\n    return lr\n\nprint(color.BOLD_COLOR + 'Done!' + color.END)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['#9AC1E9', '#FFD480', '#FF9494']\nepochs = 20\nepochs_range = [i for i in range(50 if epochs < 50 else epochs)]\nlearn_rate = [lrfn(x) for x in epochs_range]\n\nfig,ax = plt.subplots(figsize = (10,5))\nfig.patch.set_facecolor('#f5f6f6')\nax.set_facecolor('#f5f6f6')\n\nfor loc in ['right','top',]:\n    ax.spines[loc].set_visible(False)\n    \n    \nax.plot(epochs_range,learn_rate,linewidth = 4,color = colors[0])\nplt.xlabel('Range of epochs',{'fontfamily':'serif','size':14,'color':'black','weight':'bold'})\nplt.ylabel('Learning rate in 10^-5',\n           {'fontfamily':'serif','size':14,'color':'black','weight':'bold'})\n\nplt.gcf().text(0,1.06,'Hey Siri! is it a cat or dog ?: Learning Rate Schedule',\n              {'fontfamily':'serif','size':24,'color':'black','weight':'bold'})\n\nplt.gcf().text(0,0.975,'''\\nInitially set a learning rate that linearly increase from 1e-08 to 3e-5 and\n                later exponentially decreases from 3e-5 to 1e-6''',\n               {'fontfamily':'serif','size':14,'color':'black',})\n\nplt.gcf().text(0.75,0,'Made by trinhminh/Kaggle',\n               {'fontfamily':'serif','size':12,'color':'black'})\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(color.BOLD_COLOR + '\\n Agumenting Train, Validation images... and testing images just passing through...\\n' \n      + color.END)\n\n\ntrain_aug_map = ImageDataGenerator(\n    rotation_range = 10,\n    horizontal_flip = True,\n    fill_mode = 'nearest',\n    preprocessing_function = preprocess_input\n)\n\nres_train_data  = train_aug_map.flow_from_dataframe(\n    train_df,train_dir,\n    x_col = 'filename',\n    y_col = 'category',\n    target_size = (img_size,img_size),\n    batch_size = batch_size,\n    class_mode = 'categorical'\n)\n\nvalid_aug_map  = ImageDataGenerator(\n    preprocessing_function = preprocess_input\n)\n\nres_valid_data = valid_aug_map.flow_from_dataframe(\n    valid_df,train_dir,\n    x_col = 'filename',\n    y_col = 'category',\n    target_size = (img_size,img_size),\n    batch_size = batch_size,\n    class_mode = 'categorical'\n)\n\ntest_aug_map = ImageDataGenerator(\n    preprocessing_function = preprocess_input\n)\n\nres_test_data = test_aug_map.flow_from_dataframe(\n    test_df,train_dir,\n    x_col = 'filename',\n    y_col = None,\n    class_mode = None,\n    target_size = (img_size,img_size),\n    shuffle = False\n)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resNet = tf.keras.applications.ResNet50(\n    weights = 'imagenet',\n    include_top = False,\n    input_shape = (224,224,3)\n)\n\nresNet.trainable = False\nresNet_model = Sequential([\n    resNet,\n    Flatten(),\n    Dense(1024,activation = 'relu'),\n    Dropout(0.4),\n    Dense(2,activation = 'softmax')\n])\n\n\noptimizer = optimizers.Adam(1e-5)\n\nprint(color.BOLD_COLOR + '\\nResNet based Transfer learning Model layers and output shapes with params...\\n' + color.END)\nprint(color.BOLD)\nresNet_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(color.BOLD_COLOR + '\\nSetting early stopping factor and learning rate schedule\\n' + color.END)\n\nearlystop = EarlyStopping(patience=5)\n\nlr_callback = LearningRateScheduler(lrfn,verbose = True)\n\ncallbacks = [earlystop,lr_callback]\nprint(color.BOLD_COLOR + 'Done!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resNet_model.compile(\n    optimizer = optimizer,\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n)\n\nprint(color.BOLD_COLOR + 'Training on ResNet50 has started.....\\n' + color.END)\nprint(color.BOLD)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_history = resNet_model.fit_generator(\n    res_train_data,epochs = 15,\n    validation_data= res_valid_data,\n    validation_steps = valid_images//batch_size,\n    steps_per_epoch=train_images//batch_size,\n    callbacks = callbacks\n)\n\nprint(color.END)\nprint(color.BOLD_COLOR + 'Done!\\n' + color.END)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}